{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOAL \n",
    "the goal of this notebook is to create a metadata file that has annotation about genes in the R. pal genome\n",
    "We scrape this from a variety of sources. It will be put into a dataframe (Pandas) and that can be\n",
    "merged later with omics data if you want to do some further research\n",
    "\n",
    "\n",
    "## Notebook Outline\n",
    "\n",
    "1. import statements\n",
    "2. ID mapping via a genbank parse\n",
    "4. COG - get a functional annotatino and categorization for each protein\n",
    "5. Gene essentiality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Step 1 - imports ####\n",
    "\n",
    "from pandas import DataFrame, read_table\n",
    "import pandas as pd\n",
    "from Bio import SeqIO   # used to parse the genbank file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Step 2 - Identifier mapping #####\n",
    "## Our goal here is to Parse the R pal genbank files \n",
    "## to create a mapping between RefSeq accessions and the locus tag\n",
    "## specifically the old_locus_tag because that is what is in the paper https://www.ncbi.nlm.nih.gov/pubmed/26712940\n",
    "\n",
    "\n",
    "Rpal_genbank_file = \"R_pal_aux_files\\R_pal_chromosome_NC_005296.gb\"\n",
    "Rpal_chromosome = SeqIO.read(Rpal_genbank_file, \"genbank\")\n",
    "Rpal_data = [] #temp storage for later merging\n",
    "\n",
    "for feature in Rpal_chromosome.features:\n",
    "    #step 1. I only care about CDS features and not gene features (which lack a lot of information)\n",
    "    if not feature.type == 'CDS':\n",
    "        continue\n",
    "    #print (feature)\n",
    "    # step 2, because I am working with the Essentail genes paper, I only really care\n",
    "    # about proteins that I can map back to that paper using the old_locus_tag\n",
    "    if not 'old_locus_tag' in feature.qualifiers:\n",
    "        continue\n",
    "    if not 'protein_id' in feature.qualifiers:\n",
    "        continue\n",
    "    ### Okay, now to things we care about\n",
    "    acc = feature.qualifiers['protein_id'][0]# get the zero-th element in a list of len 1\n",
    "    locus = feature.qualifiers['old_locus_tag'][0]\n",
    "\n",
    "    gene_product = feature.qualifiers['product'][0]\n",
    "    ### As an added bonus, we can probably get a COG out of most of these\n",
    "    COG = None #default value\n",
    "    if 'function' in feature.qualifiers:\n",
    "        functions = feature.qualifiers[\"function\"][0] #list len 1. again.\n",
    "        #now parse out the function\n",
    "        ##   InterPro IPR000485 COGs COG1522\n",
    "        ##   COGs COG0526\n",
    "        ##################### WARNING. hack below ##################\n",
    "        # some parsing based on what I've seen before. not robust parsing to other formats\n",
    "        #print (functions)\n",
    "        Bits = functions.split(\" \") #split on space\n",
    "        if Bits[0] == \"COGs\":\n",
    "            COG = Bits[1]\n",
    "        if len(Bits)>2:\n",
    "            if Bits[2] == \"COGs\":\n",
    "                COG = Bits[3]\n",
    "    ### Now that I've done some parsing, we should gather this\n",
    "    Rpal_data.append({'RefSeq':acc, 'COG':COG, 'locus':locus, 'gene_product':gene_product}) # I am creating a list of dictionaries. \n",
    "    \n",
    "    \n",
    "#now after the file parsing loop, make my dataframe 'df'\n",
    "df = pd.DataFrame(data=Rpal_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Step 3 - COG  ####\n",
    "#### Step 3.1 COG identifiers matched to COG categories\n",
    "## the goal here is to parse the COG type file\n",
    "COG_categories_file = \"COG\\cognames2003-2014.txt\"\n",
    "Handle = open(COG_categories_file, 'r')\n",
    "Header = Handle.readline()\n",
    "\n",
    "COG_data = [] #list of dictionaries\n",
    "\n",
    "for line in Handle:\n",
    "    Bits = line.strip().split(\"\\t\")\n",
    "    COG = Bits[0]\n",
    "    category = Bits[1]\n",
    "    if len(category)> 1:\n",
    "        #print (category)\n",
    "        category = category[0] # hack for the minute, because I don't want to have something with multiple categories\n",
    "    COG_data.append({'COG':COG, 'COG_category':category})\n",
    "Handle.close()\n",
    "\n",
    "#now make a temp data frame and merge it back into the big one.\n",
    "df_temp = pd.DataFrame(data=COG_data)\n",
    "df = df.merge(df_temp, left_on='COG', right_on=\"COG\", how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### step 3.2 - COG meta categories ####\n",
    "\n",
    "##we want a simpler column for COG category, something like a meta-category\n",
    "meta_category = []\n",
    "#metabolite meta category  'M'\n",
    "things_in_M = ['G', 'E', 'F', 'H', 'I', 'P', 'Q', 'C']\n",
    "things_in_M.sort()\n",
    "for thing in things_in_M:\n",
    "    meta_category.append({'COG_category':thing, 'COG_meta':'M'})\n",
    "#transcription translation meta category 'T'\n",
    "things_in_T = ['J', 'A', 'K', 'L', 'B', 'D']\n",
    "things_in_T.sort()\n",
    "for thing in things_in_T:\n",
    "    meta_category.append({'COG_category':thing, 'COG_meta':'T'})\n",
    "#other meta category 'O'\n",
    "things_in_O = ['V', 'T', 'M', 'N', 'U', 'O', 'R', 'S']\n",
    "things_in_O.sort()\n",
    "for thing in things_in_O:\n",
    "    meta_category.append({'COG_category':thing, 'COG_meta':'O'})\n",
    "    \n",
    "##Categories that didn't have anything, so they are left out\n",
    "# X Mobilome: prophages, transposons\n",
    "# Z Cytoskeleton\n",
    "# W Extracellular structures\n",
    "# Y Nuclear structure\n",
    "    \n",
    "#meta_category.append({'COG_category':'EH', 'COG_meta':'M'})#there are so many two letter combos. Not sure how to deal with it.\n",
    "\n",
    "#now merge this new meta_category stuff into the main data frame df\n",
    "df_temp = pd.DataFrame(data=meta_category)\n",
    "df = df.merge(df_temp, left_on='COG_category', right_on=\"COG_category\", how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Step 4 - essential genes ####\n",
    "#### Step 4.1 - essential genes from PMID 26712940 - a paper about aerobic growth\n",
    "\n",
    "Rpal_essentials_file = \"R_pal_aux_files\\R_pal_essential_PMID_26712940.txt\"\n",
    "Handle = open(Rpal_essentials_file, 'r')\n",
    "Header1 = Handle.readline()\n",
    "Header2 = Handle.readline() # it has two header lines. whatever.\n",
    "Essential_data = [] #temp storage for later merging\n",
    "#all we want is the list of whether something is essential or not\n",
    "#everything in this file *is essential*, so that's why it's hardcoded\n",
    "for line in Handle.readlines():\n",
    "    Bits = line.strip().split(\"\\t\")\n",
    "    Rpal_locus_id = Bits[0]\n",
    "    Essential_data.append({'Essential_aerobic':True ,'locus':Rpal_locus_id})\n",
    "    \n",
    "Handle.close()\n",
    "df_temp = pd.DataFrame(data=Essential_data) #now make a temp data frame and merge it back into the big one.\n",
    "df = df.merge(df_temp, left_on='locus', right_on=\"locus\", how='left')\n",
    "## the default value of merging is to put 'NaN' for null. This is a problem for plotting and logic stuff\n",
    "df['Essential_aerobic'].fillna(False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Step 4.2 - essential genes from PMID 28677146 - a paper about phototrophic growth\n",
    "## this list is pre-filtered by Carrie Harwood to have no overlap with the aerobic growth\n",
    "\n",
    "Rpal_essentials_file = \"R_pal_aux_files\\R_pal_essential_PMID_28677146.txt\"\n",
    "Handle = open(Rpal_essentials_file, 'r')\n",
    "Header1 = Handle.readline()\n",
    "Header2 = Handle.readline() # it has two header lines. whatever.\n",
    "Essential_data = [] #temp storage for later merging\n",
    "#all we want is the list of whether something is essential or not\n",
    "#everything in this file *is essential*, so that's why it's hardcoded\n",
    "for line in Handle.readlines():\n",
    "    Bits = line.strip().split(\"\\t\")\n",
    "    Rpal_locus_id = Bits[0]\n",
    "    Essential_data.append({'Essential_phototrophic':True ,'locus':Rpal_locus_id})\n",
    "    \n",
    "Handle.close()\n",
    "df_temp = pd.DataFrame(data=Essential_data) #now make a temp data frame and merge it back into the big one.\n",
    "df = df.merge(df_temp, left_on='locus', right_on=\"locus\", how='left')\n",
    "## the default value of merging is to put 'NaN' for null. This is a problem for plotting and logic stuff\n",
    "df['Essential_phototrophic'].fillna(False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Step 4.3 - essential Genes for PMID 29184015  - a paper about longevity\n",
    "## this list is pre-filtered by Carrie Harwood to have no overlap with the aerobic growth\n",
    "\n",
    "Rpal_essentials_file = \"R_pal_aux_files\\R_pal_essential_PMID_29184015.txt\"\n",
    "Handle = open(Rpal_essentials_file, 'r')\n",
    "Header1 = Handle.readline()\n",
    "Header2 = Handle.readline() # it has two header lines. whatever.\n",
    "Essential_data = [] #temp storage for later merging\n",
    "\n",
    "for line in Handle.readlines():\n",
    "    Bits = line.strip().split(\"\\t\")\n",
    "    #for starters, all we want is the list of whether something is essential or not\n",
    "    Rpal_locus_id = Bits[0]\n",
    "    #everything in this file *is essential*, so that's why it's hardcoded\n",
    "    Essential_data.append({'Essential_longevity':True ,'locus':Rpal_locus_id})\n",
    "    \n",
    "Handle.close()\n",
    "#now make a temp data frame and merge it back into the big one.\n",
    "df_temp = pd.DataFrame(data=Essential_data)\n",
    "df = df.merge(df_temp, left_on='locus', right_on=\"locus\", how='left')\n",
    "## the default value of merging is to put 'NaN' for null. This is a problem if you want to explicity\n",
    "## use the True and False keywords for a binary column. The 'NaN' will not get plotted.\n",
    "df['Essential_longevity'].fillna(False, inplace=True) # have to fill in the value, or else it will not plot the 'false' group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### Step 5 - Pfam\n",
    "\n",
    "#now trying to merge in the PFam assignments which are made via Uniprot,\n",
    "#which has to get merged from the locus name\n",
    "Pfam_array = []\n",
    "from Bio import SwissProt\n",
    "handle = open('R_pal_aux_files\\R_pal_proteome.sp')\n",
    "for record in SwissProt.parse(handle):\n",
    "    gene_name = record.gene_name\n",
    "    locus = None\n",
    "    #Name=hbaA; OrderedLocusNames=RPA0669;\n",
    "    for bit in gene_name.split(\";\"):\n",
    "        if bit[:7] == 'Ordered':\n",
    "            (blah, locus) = bit.split(\"=\")\n",
    "            # occasionally we get something like OrderedLocusNames=RPA3337 {ECO:0000313|EMBL:CAE28778.1};\n",
    "            if ' ' in locus:\n",
    "                locus = locus.split(' ')[0] #split on the space and take the first thing\n",
    "            break\n",
    "    if not locus:\n",
    "        #we don't have anything to merge on later, so we might as well quit\n",
    "        continue\n",
    "    DRs = record.cross_references # a list of tuples\n",
    "    for DR in DRs:\n",
    "        if DR[0] == 'Pfam': # now we care\n",
    "            (Pfam_ID, Pfam_name) = (DR[1], DR[2])\n",
    "            Pfam_array.append({'locus':locus, 'Pfam_ID':Pfam_ID, 'Pfam_name':Pfam_name})\n",
    "df_temp = pd.DataFrame(data=Pfam_array)\n",
    "\n",
    "df = df.merge(df_temp, left_on='locus', right_on='locus', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### save dataframe ####\n",
    "out_filename = \"R_pal_metadata_df.txt\"\n",
    "df.to_csv(out_filename, sep=\"\\t\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
